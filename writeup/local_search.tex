% 1. in union-find subsection make function names in text a different
%    font
% 2. include parameters of size-constrained add-edge on randomized graph
%    in table
% 3. more analysis of SC AE results
%#######################################################################

We introduce several algorithms for generating brain parcellations. The
algorithms in this chapter are all local search heuristics; they begin
with $N$ unconnected vertices and iteratively join adjacent ones into
components until some stopping criterion is met.

For each algorithm, the resulting parcellation is presented, discussed,
and evaluated according to the criteria introduced in the previous
chapter.

\section{Unconstrained Add-Edge}

The first and simplest algorithm starts with an empty graph of $N$
vertices and sequentially adds edges between adjacent voxels in order of
highest sample distance correlation, until the graph has some pre-
specified number of connected components $K$.

We will refer to this algorithm as \"Unconstrained Add-Edge\". A naive
implementation of would re-compute the number of connected components in
the graph (using linear-time bread-first or depth-first search) after
each addition of an edge, resulting in a costly $O(EN)$ time complexity.
A more efficient implementation takes advantage of the fact that each
addition of an edge decreases the number of components in the graph by
at most 1. Hence the algorithm needs only to compute the number of
connected components after adding $k - K$ edges, where $k$ is the
current number of connected components of the graph, beginning at $N$.

\begin{verbatim}
k := N
i := 1
while k > K
    repeat k - K times
        add the ith highest-weighted edge to the graph
        i := i + 1
    end
    k := compute number of connected components
end
\end{verbatim}

Another implementation uses a binary search-type strategy and is
$O((N + E) \log E)$. The idea is to \"search\" for the last edge to add
to the graph by maintaining a range of possible last edges. In each
iteration, the algorithm would add to the graph edges 1 to the midpoint
of this range, compute the number of connected components, and adjust
the range based on whether the number of components is higher or lower
than the target $K$.

\begin{verbatim}
l := 1
h := E
repeat
    m := (l + h) / 2
    add edges from 1 to m to an empty graph
    k := compute number of connected components
    if k = K
        done
    else if k < K
        h := m
    else if k > K
        l := m
    end
end
\end{verbatim}

The Unconstrained Add-Edge algorithm produces severely imbalanced
parcellations. In the 100-component graph, there was one component
containing over 99.9\% of all the vertices in the graph. The following
algorithm introduces a modification that address this issue.

\section{Size-Constrained Add-Edge}

The Size-Constrained Add-Edge algorithm works in a similar manner to the
Unconstrained version, adding edges to the graph in decreasing order of
distance correlation. The Size-Constrained version differs by applying
a filter to each edge considered, adding the edge only if at least one
of the two following conditions are met:

\begin{enumerate}[1.]
\item
At least one of the two components bridge by the edge is of size less
than some prespecified parameter $s_{\min}$.

\item
The union of the two components is of size $\leq s_{\max}$.
\end{enumerate}

Letting $K$ denote the target number of components in the graph, the
Size-Constrained Add-Edge algorithm can be written as:

\begin{verbatim}
sort edges in decreasing energy correlation order
k := N, number of components
for e = 1, ..., E
    (i, j) := vertices of edge e
    I := component containing i
    J := component containing j
    if I = J
        continue
    else if (size(I) < s_min or size(J) < s_min)
            or size(I + J) <= s_max
        add e to the graph
        k := k - 1
        if number of components = K
            break
        end
    end
end
\end{verbatim}

The naive implementation must use BFS/DFS in each iteration to compute
the size of components $I$ and $J$, and hence must have time complexity
$O(EN)$. Fortunately, there is a way to sub-linearly update information
on the components of the graph, using the union-find data structure.

\subsection{Union-Find}

The core Union-Find data structure begins with an empty graph of $N$
vertices and supports two operations. union(i, j) adds an edge between
vertices $i$ and $j$. root(i) returns an identifier for the component
to which vertex $i$ belongs. All vertices in the same component have the
same root. We modified Union-Find to support an additional operation.
component\_size(i) returns the number of vertices belonging to the
component containing $i$.

Union-Find represents each component as a rooted tree, with vertices in
the graph mapping to nodes in the tree. Information about the tree is
stored in two arrays of length $N$, parent and size, which are subject
to the following invariants.

\begin{enumerate}[1.]
\item
For each node i, parent[i] = node i's parent on the tree, unless i is a
root node. If i is a root node, then parent[i] = i.

\item
Nodes i and j are in the same component if and only if they are in the
same tree, if and only if they share the same root node.

\item
If i is a root node, then size[i] = the size of the component, or the
number of nodes in the tree. If i is not a root node, then size[i] can
be anything.
\end{enumerate}

A baseline implementation of the three functions is

\begin{verbatim}
function root(i)
    while parent[i] != i
        i := parent[i]
    end
    return i
end

function union(i, j)
    parent[root(j)] := root(i)
end

function component_size(i)
    return size[root(i)]
end
\end{verbatim}

In addition to the baseline code above, there are two important
optimizations:

\begin{enumerate}[1.]
\item
Weighted union maintains information of the sizes of each component so
that the root of the smaller component always becomes a child of the
larger component's root.

\item
Path compression flattens the tree with each call to root. Specifically,
when root is called on node $i$, each node traversed from $i$ to the
root has its parent set to be the root.
\end{enumerate}

With these two optimizations, the time complexity of root, union, and
component\_size was proven in (Hopcroft 1973) to be at least as good as
$O(\log^* N)$ where $\log^*$ is the iterated logarithm, defined as the
number of times the natural log must be applied to $N$ so that it
becomes less than or equal to 1.

\subsection{Results of Size-Constrained Add-Edge Parcellation}

We ran Size-Constrained Add-Edge on the distance correlation graph and
on a copy of the graph with randomized edge weights. We used
parcellation criteria discussed in chapter 3 to evaluate the quality of
the two resulting parcellations on the fMRI data used to generate the
distance correlation graph. The results of the in-sample evaluation are
shown in the table below:

\begin{tabular}{c c | c c c c}
    $s_{\min}$ & $s_{\max}$ & Within & Adjacent & Between & Boundary \\
    \hline
    \input{4_constrained_addedge.txt}
\end{tabular}

The criterion that has seen the most significant improvement compared
with the random graph parcellation is the Boundary-Score, with a
decrease from 0.719 in the random graph parcellation to the range of
0.514 - 0.521. The Within- and Adjacent-Scores saw smaller but still
noticeable improvements, and Between-Score saw no improvement from the
random baseline.

We display the parcellation obtained from setting parameters
$s_{\min} = 1000$ and $s_{\max} = 7500$ below. While the sizes of the
parcels are much more balanced than the result of the Unconstrained
Add-Edge, there are still noticeable differences in parcel size.

\begin{center}
\includegraphics[scale = 0.6]{4_scae_1000_7500_axial.png}

Axial

\includegraphics[scale = 0.6]{4_scae_1000_7500_coronal.png}

Coronal

\includegraphics[scale = 0.6]{4_scae_1000_7500_sagittal.png}

Sagittal
\end{center}
\section{Edge Contraction}

The Edge-Contraction algorithm attempts to address two problems of
the Size-Constrained Add-Edge algorithm: poor Adjacent-Score relative
to randomized graph and unbalanced parcels. We hypothesized that one
reason for a relatively low Adjacent-Score might be the following
scenario: when a vertex is added to a component, it might have multiple
edges to that component. One edge might have a very high weight; this is
the one that is officially \"added\". However, the other edges with far
lower weights are implicitly added as well, lowering the average edge
weights within the component.

The Edge-Contraction algorithm handles this issue by maintaining that
there can be at most one edge between any two components A and B, and
further that the weight on such an edge is the mean of the weights on
all edges that connect a vertex in A with a vertex in B.

The graph starts out with $N$ components, each a single vertex. In every
iteration

\begin{enumerate}[1.]
\item
The smallest component with the largest edge to another component is
selected.

\item
This largest edge is contracted, fusing two adjacent components to form
a larger-sized component.

\item
For all components adjacent to the fused component, all edges connecting
them to the fused component are averaged into a single edge.
\end{enumerate}

In short, the Edge-Contraction algorithm is a greedy heuristic that
attempts to achieve the two objectives of balancing component size
and maximizing the average edge weight within each component.

\subsection{Implementation using Augmented Adjacency List}


\subsection{Optimal Number of Components}

The Edge-Contraction algorithm has the benefit of requiring only one
parameter, the target component number. We assessed the validity of EC
parcellations with varying numbers of components. The plots below show
how the Adjacent-Score and Boundary-Score varied according to the
number of components in the EC algorithm. The peak in the Adjacent-Score
occurred at 6 components.

\includegraphics[scale = 0.8]{4_ec_sizes.png}

\begin{center}

\end{center}